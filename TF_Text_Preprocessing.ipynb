{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPE2vZz0qyuKmKBwTdiKKCy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/it5joys135/ML-Projects/blob/main/TF_Text_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zjgot6xjTZ70",
        "outputId": "c183e94b-3429-449c-8f66-3c904ff1e13e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.1\n",
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "Uz7-LLJIT2yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tiny dataset\n",
        "sentences = [\n",
        "    \"I like eggs and ham.\",\n",
        "    \"I love chocolate and bunnies.\",\n",
        "    \"I hate onions.\"\n",
        "]"
      ],
      "metadata": {
        "id": "EDkq0KlLUIcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB_SIZE = 20000"
      ],
      "metadata": {
        "id": "6f2-gsn7Ua64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorization_layer = TextVectorization(\n",
        "    max_tokens = MAX_VOCAB_SIZE,\n",
        "    # standardize = \"lower_and_strip_punctuation\",\n",
        "    # split = \"whitespace\",\n",
        "    # output_mode = \"int\",\n",
        ")"
      ],
      "metadata": {
        "id": "L6Xmprk3Um7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorization_layer.adapt(sentences)"
      ],
      "metadata": {
        "id": "8K12XXoHVLHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = vectorization_layer(sentences)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9wQvdrmVc1J",
        "outputId": "d564336b-7506-49de-8a69-19c30c206fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 2  6  9  3  8]\n",
            " [ 2  5 10  3 11]\n",
            " [ 2  7  4  0  0]], shape=(3, 5), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorization_layer.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp4bSzzXVtog",
        "outputId": "a3950e31-2e11-4691-fe1d-6fc1a3f1b3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'i',\n",
              " 'and',\n",
              " 'onions',\n",
              " 'love',\n",
              " 'like',\n",
              " 'hate',\n",
              " 'ham',\n",
              " 'eggs',\n",
              " 'chocolate',\n",
              " 'bunnies']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How do we get word-to-index mapping?\n",
        "word_2_idx = {v:k for k, v in enumerate(vectorization_layer.get_vocabulary())}\n",
        "print(word_2_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-b8ZnFuWFPk",
        "outputId": "cc53760c-2819-4836-e3d6-3ef61f2674e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': 0, '[UNK]': 1, 'i': 2, 'and': 3, 'onions': 4, 'love': 5, 'like': 6, 'hate': 7, 'ham': 8, 'eggs': 9, 'chocolate': 10, 'bunnies': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# truncation\n",
        "vectorization_layer_truncated = TextVectorization(\n",
        "    max_tokens = MAX_VOCAB_SIZE,\n",
        "    output_sequence_length = 3\n",
        ")\n",
        "\n",
        "# fit\n",
        "vectorization_layer_truncated.adapt(sentences)\n",
        "\n",
        "# vectorize\n",
        "sequences_truncated = vectorization_layer_truncated(sentences)\n",
        "print(sequences_truncated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxmtofE8Wx50",
        "outputId": "a95be6bb-9feb-4e3d-a3bb-bc4c885655f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 2  6  9]\n",
            " [ 2  5 10]\n",
            " [ 2  7  4]], shape=(3, 3), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ragged (No Padding) (TF backend only)\n",
        "vectorization_layer_ragged = TextVectorization(\n",
        "    max_tokens = MAX_VOCAB_SIZE,\n",
        "    ragged=True\n",
        ")\n",
        "\n",
        "# fit\n",
        "vectorization_layer_ragged.adapt(sentences)\n",
        "\n",
        "# vectorize\n",
        "sequences_ragged = vectorization_layer_ragged(sentences)\n",
        "print(sequences_ragged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-jIlsu3Xt18",
        "outputId": "a8e570d8-0d50-4b96-9a52-afb8887dd7ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[2, 6, 9, 3, 8], [2, 5, 10, 3, 11], [2, 7, 4]]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pad at front instead of back\n",
        "# not support in TextVectorization layer itself\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "\n",
        "# default\n",
        "# tf.keras.utils.pad_sequences(\n",
        "#     sequences,\n",
        "#     maxlen=None,\n",
        "#     dtype='int32',\n",
        "#     padding='pre',\n",
        "#     truncating='pre',\n",
        "#     value=0.0\n",
        "# )\n",
        "\n",
        "padded = pad_sequences(sequences_ragged.to_list())\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g5bLwSZYmLp",
        "outputId": "b640b295-4418-4ae6-9749-be66c6aeae6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  6  9  3  8]\n",
            " [ 2  5 10  3 11]\n",
            " [ 0  0  2  7  4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oxnXgUqIaPDg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}